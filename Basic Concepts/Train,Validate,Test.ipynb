{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367094e6-f66d-4425-b869-0f1c82cbec94",
   "metadata": {},
   "source": [
    "Dataset is divided into 3 categories:        \n",
    "1)Training Dataset              \n",
    "2)Validation Dataset         \n",
    "3)Test Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b7abc74-a8de-48a1-8fce-63d1c42c97b1",
   "metadata": {},
   "source": [
    "Training dataset is used to train the model.The model uses a training data set to understand the patterns and relationships within the data, thereby learning to make predictions or decisions without being explicitly programmed to perform a specific task.\n",
    "\n",
    "Validation datset is used to fine-tune the hyperparameters of the model and is considered a part of the training of the model. The model only sees this data for evaluation but does not learn from this data, providing an objective unbiased evaluation of the model.A validation dataset tells us how well the model is learning and adapting, allowing for adjustments and optimizations to be made to the model's parameters or hyperparameters before it's finally put to the test.Cross-validation (CV) techniques come into play during this phase.\n",
    "That said, not all models require validation sets.ML models with no hyperparameters or those that do not have tuning options do not need a validation set.\n",
    "\n",
    "Test dataset is a separate sample, an unseen data set, to provide an unbiased final evaluation of a model fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab01f9b-97d6-495b-874d-0dc1afa2d986",
   "metadata": {},
   "source": [
    "Difference between validation and testing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cee68bf5-7f39-430f-a531-d06e6966ab6d",
   "metadata": {},
   "source": [
    "The difference is that while validating, the results provide metrics as feedback to train the model better. In contrast, the performance of a test procedure merely confirms that the model works overall, i.e. as a black box with inputs passed through it. During this final evaluation, there is no adjustment of hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b69600a-4f17-44f3-b54d-e26224cbae3d",
   "metadata": {},
   "source": [
    "How to Split Your Machine Learning Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0700b8b-a3a0-4914-aade-6c7fa5daecdc",
   "metadata": {},
   "source": [
    "The proportion of train, test, and validation data can vary depending on the specific problem, the size of the dataset, and the available resources. However, a commonly used rule of thumb is to allocate approximately 70-80% of the data for training, 10-15% for testing, and 10-15% for validation. This split is a general guideline and can be adjusted based on the specific requirements of your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de398e-b821-4c18-9316-303106c64335",
   "metadata": {},
   "source": [
    "Cross Validation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6994af21-c3dd-4710-9af3-723687cd178d",
   "metadata": {},
   "source": [
    "It involves dividing the available data into multiple folds or subsets, using one of these folds as a validation set, and training the model on the remaining folds. This process is repeated multiple times, each time using a different fold as the validation set. Finally, the results from each validation step are averaged to produce a more robust estimate of the model’s performance.\n",
    "\n",
    "There are several types of cross validation techniques, including k-fold cross validation, leave-one-out cross validation, and Holdout validation, Stratified Cross-Validation. The choice of technique depends on the size and nature of the data, as well as the specific requirements of the modeling problem.\n",
    "\n",
    "1)Holdout Validation - we perform training on the 50% of the given dataset and rest 50% is used for the testing purpose.\n",
    "problem - higher bias.\n",
    "\n",
    "2)LOOCV (Leave One Out Cross Validation) - In this method, we perform training on the whole dataset but leaves only one data-point of the available dataset and then iterates for each data-point.In LOOCV, the model is trained on n-1    samples and tested on the one omitted sample, repeating this process for each data point in the dataset.The major drawback of this method is that it leads to higher variation in the testing model as we are testing against one data point. If the data point is an outlier it can lead to higher variation. Another drawback is it takes a lot of execution time as it iterates over ‘the number of data points’ times.\n",
    "\n",
    "3)Stratified Cross-Validation - The dataset is divided into k folds while maintaining the proportion of classes in each fold.During each iteration, one-fold is used for testing, and the remaining folds are used for training.The process is repeated k times, with each fold serving as the test set exactly once.\n",
    "This is particularly important when dealing with imbalanced datasets, where certain classes may be underrepresented.\n",
    "\n",
    "4)K-Fold Cross Validation - In K-Fold Cross Validation, we split the dataset into k number of subsets (known as folds) then we perform training on the all the subsets but leave one(k-1) subset for the evaluation of the trained model. In this method, we iterate k times with a different subset reserved for testing purpose each time.\n",
    "It is always suggested that the value of k should be 10 as the lower value of k is takes towards validation and higher value of k leads to LOOCV method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfacaac4-a9e0-4d9e-9404-e6d875ceaee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
